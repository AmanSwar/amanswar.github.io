<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects | Aman Swar</title>
    <meta name="description"
        content="Selected works in AI Systems Engineering, High-Performance Computing, and Distributed Systems.">
    <link rel="stylesheet" href="assets/style.css">
</head>

<body>
    <header>
        <div class="container">
            <a href="index.html" class="logo">Aman<span>Swar</span></a>
            <nav>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="projects.html" class="highlight">Projects</a></li>
                    <li><a href="index.html#about">About</a></li>
                    <li><a href="index.html#contact">Contact</a></li>
                    <li><a href="assets/resume.pdf" target="_blank">Resume_</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section id="projects">
            <div class="container">
                <h2 style="margin-top: 80px;">Selected <span class="highlight">Works</span></h2>
                <div class="project-grid">
                    <!-- Torch++ -->
                    <div class="project-card">
                        <span class="project-metric">9.39× Speedup</span>
                        <h3>Torch++</h3>
                        <p>A powerful extension library for PyTorch, designed to supercharge your deep learning
                            workflows with high-performance CUDA kernels and a distributed training framework.</p>
                        <div class="tech-stack">
                            <span class="tech-badge">CUDA</span>
                            <span class="tech-badge">PyTorch</span>
                            <span class="tech-badge">C++</span>
                            <span class="tech-badge">Distributed Systems</span>
                        </div>
                        <div class="project-links">
                            <a href="project/torchpp.html" class="link-item">View Details &rarr;</a>
                            <a href="https://github.com/AmanSwar/TorchPlusPlus" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- KernelLab -->
                    <div class="project-card">
                        <span class="project-metric">Maintained</span>
                        <h3>KernelLab</h3>
                        <p>A library of high-performance GPU kernels written in CUDA and Triton. It serves as a
                            practical guide and reference for GPU programming, demonstrating various optimization
                            strategies.</p>
                        <div class="tech-stack">
                            <span class="tech-badge">CUDA</span>
                            <span class="tech-badge">Triton</span>
                            <span class="tech-badge">C++</span>
                        </div>
                        <div class="project-links">
                            <a href="project/kernellab.html" class="link-item">View Details &rarr;</a>
                            <a href="https://github.com/AmanSwar/KernelLab" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- DistJax -->
                    <div class="project-card">
                        <span class="project-metric">Active</span>
                        <h3>DistJax</h3>
                        <p>A powerful and flexible library for JAX that simplifies the implementation of distributed
                            training for large-scale neural networks. Provides high-level abstractions for common
                            parallelism strategies.</p>
                        <div class="tech-stack">
                            <span class="tech-badge">JAX</span>
                            <span class="tech-badge">Python</span>
                            <span class="tech-badge">Distributed Systems</span>
                        </div>
                        <div class="project-links">
                            <a href="project/distjax.html" class="link-item">View Details &rarr;</a>
                            <a href="https://github.com/AmanSwar/DistJax" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- FastQwen3 -->
                    <div class="project-card">
                        <span class="project-metric">9.25× Latency Reduction</span>
                        <h3>FastQwen3</h3>
                        <p>Qwen3 language model, optimized for high-performance inference leveraging custom CUDA kernels
                            and FlashAttention to achieve 9.3x++ speedup over the baseline Hugging Face implementation.
                        </p>
                        <div class="tech-stack">
                            <span class="tech-badge">CUDA</span>
                            <span class="tech-badge">Triton</span>
                            <span class="tech-badge">PyTorch</span>
                        </div>
                        <div class="project-links">
                            <a href="project/fastinference.html" class="link-item">View Details &rarr;</a>
                            <a href="https://github.com/AmanSwar/FastQwen3" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- GEMM -->
                    <div class="project-card">
                        <span class="project-metric">Completed</span>
                        <h3>GEMM</h3>
                        <p>Collection of General Matrix Multiplication (GEMM) kernels implemented in CUDA C++. Explores
                            various optimization techniques, from basic naive implementations to highly optimized
                            kernels using Tensor Cores.</p>
                        <div class="tech-stack">
                            <span class="tech-badge">CUDA</span>
                            <span class="tech-badge">C++</span>
                            <span class="tech-badge">Assembly</span>
                        </div>
                        <div class="project-links">
                            <a href="project/gemm.html" class="link-item">View Details &rarr;</a>
                            <a href="https://github.com/AmanSwar/GEMM" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- TorchSSL -->
                    <div class="project-card">
                        <span class="project-metric">Maintained</span>
                        <h3>TorchSSL</h3>
                        <p>A PyTorch-based library designed to provide a clean, modular, and high-performance
                            environment for self-supervised learning with visual representations.</p>
                        <div class="tech-stack">
                            <span class="tech-badge">PyTorch</span>
                            <span class="tech-badge">SSL</span>
                        </div>
                        <div class="project-links">
                            <a href="project/torchssl.html" class="link-item">View Details &rarr;</a>
                            <a href="https://github.com/AmanSwar/TorchSSL" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- RetinaSys -->
                    <div class="project-card">
                        <span class="project-metric">90.73% QWK</span>
                        <h3>RetinaSys</h3>
                        <p>Production-ready diabetic retinopathy detection system optimized for edge deployment.
                            Combines DINOv2 features with efficient architectures.</p>
                        <div class="tech-stack">
                            <span class="tech-badge">PyTorch</span>
                            <span class="tech-badge">Edge AI</span>
                            <span class="tech-badge">ONNX</span>
                        </div>
                        <div class="project-links">
                            <a href="project/retinasys.html" class="link-item">View Details &rarr;</a>
                            <a href="https://github.com/AmanSwar/DR-detection" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- SearchSphere -->
                    <div class="project-card">
                        <span class="project-metric">Completed</span>
                        <h3>SearchSphere</h3>
                        <p>A standalone, AI-powered semantic search engine that runs locally on a user's machine.
                            Designed to overcome the limitations of traditional keyword-based file search.</p>
                        <div class="tech-stack">
                            <span class="tech-badge">Transformers</span>
                            <span class="tech-badge">Vector Search</span>
                        </div>
                        <div class="project-links">
                            <a href="project/searchsphere.html" class="link-item">View Details &rarr;</a>
                            <a href="https://github.com/AmanSwar/SearchSphere" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- ModelGoBrr -->
                    <div class="project-card">
                        <span class="project-metric">Active</span>
                        <h3>ModelGoBrr...</h3>
                        <p>A playground for experimentation to make Transformer based and Diffusion model run faster
                            (both training and inference).</p>
                        <div class="tech-stack">
                            <span class="tech-badge">PyTorch</span>
                            <span class="tech-badge">CUDA</span>
                            <span class="tech-badge">JAX</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/AmanSwar/ModelGoBrr" class="link-item" target="_blank">GitHub
                                &rarr;</a>
                        </div>
                    </div>

                    <!-- ML Stocks -->
                    <div class="project-card">
                        <span class="project-metric">Completed</span>
                        <h3>ML Stocks</h3>
                        <p>Stock prediction application that uses several machine learning and deep learning models to
                            forecast stock prices. Powered by FastAPI and Gradio.</p>
                        <div class="tech-stack">
                            <span class="tech-badge">FastAPI</span>
                            <span class="tech-badge">Gradio</span>
                        </div>
                        <div class="project-links">
                            <a href="https://huggingface.co/spaces/AlgoX/mlStocks-pred/tree/main" class="link-item"
                                target="_blank">GitHub &rarr;</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Aman Swar. Built with performance in mind.</p>
        </div>
    </footer>
</body>

</html>